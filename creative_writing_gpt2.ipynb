{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "name": "creative-writing-gpt2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/avchs/creative-writing-with-gpt2/blob/master/creative_writing_gpt2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xb6Xo3Or8bRz"
      },
      "source": [
        "# Cloning the creative writing code base\n",
        "\n",
        "This copies the code & data required onto the Colab notebook instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kkW9GVWGb07F",
        "outputId": "2377053e-ee97-490d-d148-ab9f88236b4f"
      },
      "source": [
        "!rm -rf /content/creative-writing-with-gpt2 /content/sample_data /content/creative\n",
        "!git clone https://github.com/ADGEfficiency/creative-writing-with-gpt2\n",
        "!mv creative-writing-with-gpt2 creative"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'creative-writing-with-gpt2'...\n",
            "remote: Enumerating objects: 144, done.\u001b[K\n",
            "remote: Counting objects: 100% (144/144), done.\u001b[K\n",
            "remote: Compressing objects: 100% (105/105), done.\u001b[K\n",
            "remote: Total 144 (delta 55), reused 124 (delta 35), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (144/144), 30.13 MiB | 31.51 MiB/s, done.\n",
            "Resolving deltas: 100% (55/55), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wflq6aRh8jqo"
      },
      "source": [
        "# Installing required packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lXCaLAob2xj",
        "outputId": "e9b63b22-5000-4e68-e330-d9d8396ba21c"
      },
      "source": [
        "!pip install -q -r /content/creative/requirements.txt\n",
        "print(' ')\n",
        "print('finished installing packages')\n",
        "\n",
        "import os \n",
        "os.makedirs('/content/creative/models', exist_ok=True)\n",
        "\n",
        "#  silence tensorflow warnings\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
        "\n",
        "import tensorflow as tf\n",
        "tf.get_logger().setLevel('INFO')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 8.6 MB 5.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 311 kB 41.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 804.1 MB 2.1 kB/s \n",
            "\u001b[K     |████████████████████████████████| 131 kB 54.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 53.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 895 kB 57.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 58 kB 4.7 MB/s \n",
            "\u001b[K     |████████████████████████████████| 428 kB 71.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 393 kB 70.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 78 kB 5.0 MB/s \n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 125 kB 72.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 69 kB 6.3 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.0 MB 33.6 MB/s \n",
            "\u001b[K     |████████████████████████████████| 79 kB 6.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 48.2 MB/s \n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.10.0+cu111 requires torch==1.9.0, but you have torch 1.8.1 which is incompatible.\n",
            "torchtext 0.10.0 requires torch==1.9.0, but you have torch 1.8.1 which is incompatible.\n",
            "google-colab 1.0.0 requires tornado~=5.1.0; python_version >= \"3.0\", but you have tornado 6.1 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[?25h \n",
            "finished installing packages\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SU7iRBi2A2Qz"
      },
      "source": [
        "# Available raw data\n",
        "\n",
        "The creative writing code base has a few clean datasets included, which can be used for fine-tuning.  You can see the text using the *Files* browser on the right."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sj3XPNvmA2bM",
        "outputId": "58c0ca55-1ac9-4814-8654-0a17d8826ca1"
      },
      "source": [
        "print('Available datasets:')\n",
        "!ls /content/creative/data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Available datasets:\n",
            "alan-watts  asimov  harry      mahabarta    plato\n",
            "art-of-war  bible   hemingway  meditations  tolkien\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0fGCXveDP3D"
      },
      "source": [
        "## Pre finetuned models available for download"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "smpVeQ2Zc5OJ",
        "outputId": "3e26ee99-5faf-4fb8-fb32-44563577c4bb"
      },
      "source": [
        "%cd /content/creative\n",
        "from models import models\n",
        "\n",
        "print('\\nAvailable pre-finetuned models:')\n",
        "for k in models.keys():\n",
        "  print(k)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/creative\n",
            "\n",
            "Available pre-finetuned models:\n",
            "alan-watts\n",
            "bible\n",
            "harry\n",
            "meditations\n",
            "tolkien\n",
            "asimov\n",
            "hemingway\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PQ9jXNCi9qyz"
      },
      "source": [
        "## Downloading pre fine-tuned models\n",
        "\n",
        "Because the size of the pretrained models is massive, I've made them available as shared links on my Google Drive.  \n",
        "\n",
        "The code below will download them to this instance of the Colab notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7M84nfFOmEub",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73e04f80-ec38-41d9-beeb-1a19ef392fc4"
      },
      "source": [
        "from models import download_models\n",
        "\n",
        "download_models(models, prefix='/content/creative/models',)\n",
        "!ls /content/creative/models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "downloading alan-watts\n",
            "Downloading 1TxMWBLuN-GLBMB3ebi5uIbq374jt6HE7 into /content/creative/models/alan-watts.zip... Done.\n",
            "downloading bible\n",
            "Downloading 1x8SQgqZyLGRdHRV6BUIHEPxZuWUCyhRc into /content/creative/models/bible.zip... Done.\n",
            "downloading harry\n",
            "Downloading 1-3iQhw89Biyv1QMf4o2BEahoPX9g3fNd into /content/creative/models/harry.zip... Done.\n",
            "downloading meditations\n",
            "Downloading 1-9TiibA0_dqD7dqyJnBNBrZnLuegAa_E into /content/creative/models/meditations.zip... Done.\n",
            "downloading tolkien\n",
            "Downloading 1-0lq9cGClSqcvcI3WqGkxdmAdoWrhD4e into /content/creative/models/tolkien.zip... Done.\n",
            "downloading asimov\n",
            "Downloading 1yg4bORU_KpV4h_aVnbMaekulK6ShpCS1 into /content/creative/models/asimov.zip... Done.\n",
            "downloading hemingway\n",
            "Downloading 1-0p2I9SCL37JEaIlIGhasbvOc4lxQIq6 into /content/creative/models/hemingway.zip... Done.\n",
            "alan-watts.zip\tbible.zip  hemingway.zip    tolkien.zip\n",
            "asimov.zip\tharry.zip  meditations.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JehZsN6M9_0f"
      },
      "source": [
        "## Using a pre fine-tuned model\n",
        "\n",
        "This can be run after either downloading a model or training your own."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5G_PcK2a9-5C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2570df98-87c8-488b-896c-0a02e0d48dfd"
      },
      "source": [
        "import os\n",
        "\n",
        "# change this to use a different model\n",
        "model = 'bible'\n",
        "# determines the amount of characters to output\n",
        "output_length = 200\n",
        "\n",
        "os.environ['MODEL'] = model  \n",
        "os.environ['OUTLEN'] = str(output_length)\n",
        "!python /content/creative/run_generation.py \\\n",
        "--model_type=gpt2 \\\n",
        "--model_name_or_path=\"/content/creative/models/$MODEL\" \\\n",
        "--length=$OUTLEN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/26/2021 00:03:00 - INFO - transformers.tokenization_utils -   Model name '/content/creative/models/bible' not found in model shortcut name list (gpt2, gpt2-medium, gpt2-large, distilgpt2). Assuming '/content/creative/models/bible' is a path or url to a directory containing tokenizer files.\n",
            "10/26/2021 00:03:00 - INFO - transformers.tokenization_utils -   Didn't find file /content/creative/models/bible. We won't load it.\n",
            "10/26/2021 00:03:00 - INFO - transformers.tokenization_utils -   Didn't find file /content/creative/models/bible. We won't load it.\n",
            "10/26/2021 00:03:00 - INFO - transformers.tokenization_utils -   Didn't find file /content/creative/models/bible/added_tokens.json. We won't load it.\n",
            "10/26/2021 00:03:00 - INFO - transformers.tokenization_utils -   Didn't find file /content/creative/models/bible/special_tokens_map.json. We won't load it.\n",
            "10/26/2021 00:03:00 - INFO - transformers.tokenization_utils -   Didn't find file /content/creative/models/bible/tokenizer_config.json. We won't load it.\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/creative/run_generation.py\", line 256, in <module>\n",
            "    main()\n",
            "  File \"/content/creative/run_generation.py\", line 185, in main\n",
            "    tokenizer = tokenizer_class.from_pretrained(args.model_name_or_path)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\", line 282, in from_pretrained\n",
            "    return cls._from_pretrained(*inputs, **kwargs)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/transformers/tokenization_utils.py\", line 346, in _from_pretrained\n",
            "    list(cls.vocab_files_names.values())))\n",
            "OSError: Model name '/content/creative/models/bible' was not found in tokenizers model name list (gpt2, gpt2-medium, gpt2-large, distilgpt2). We assumed '/content/creative/models/bible' was a path or url to a directory containing vocabulary files named ['vocab.json', 'merges.txt'] but couldn't find such vocabulary files at this path or url.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMvatmxM7s3T",
        "outputId": "cca40c93-7091-460a-a2c7-c6131eb21277"
      },
      "source": [
        "!ls /content/creative/models"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "alan-watts.zip\tbible.zip  hemingway.zip    tolkien.zip\n",
            "asimov.zip\tharry.zip  meditations.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nQhlD3_N7t0i"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}